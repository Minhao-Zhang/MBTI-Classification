{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "DATA_PATH = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{DATA_PATH}train.pkl\", 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "train, valid = train_test_split(data, test_size=0.2, random_state=42, stratify=data['mbti'], shuffle=True)\n",
    "\n",
    "y_train = train['mbti']\n",
    "X_train = train.drop('mbti', axis=1)\n",
    "y_valid = valid['mbti']\n",
    "X_valid = valid.drop('mbti', axis=1)\n",
    "\n",
    "# Convert y_train and y_valid to separate binary columns for each MBTI character\n",
    "y_train_binary = pd.DataFrame({\n",
    "    'I-E': y_train.apply(lambda x: 1 if x[0] == 'I' else 0),\n",
    "    'N-S': y_train.apply(lambda x: 1 if x[1] == 'N' else 0),\n",
    "    'T-F': y_train.apply(lambda x: 1 if x[2] == 'T' else 0),\n",
    "    'J-P': y_train.apply(lambda x: 1 if x[3] == 'J' else 0)\n",
    "})\n",
    "\n",
    "y_valid_binary = pd.DataFrame({\n",
    "    'I-E': y_valid.apply(lambda x: 1 if x[0] == 'I' else 0),\n",
    "    'N-S': y_valid.apply(lambda x: 1 if x[1] == 'N' else 0),\n",
    "    'T-F': y_valid.apply(lambda x: 1 if x[2] == 'T' else 0),\n",
    "    'J-P': y_valid.apply(lambda x: 1 if x[3] == 'J' else 0)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost Results\n",
      "Results for I-E:\n",
      "Accuracy: 0.5747063254947632\n",
      "F1 Score: 0.6809974179138345\n",
      "MCC: 0.12041243593219175\n",
      "Balanced Accuracy: 0.5734348758982699\n",
      "------------------------------\n",
      "Results for N-S:\n",
      "Accuracy: 0.5811542134703716\n",
      "F1 Score: 0.7192095502951992\n",
      "MCC: 0.09714719630339974\n",
      "Balanced Accuracy: 0.5919778953089392\n",
      "------------------------------\n",
      "Results for T-F:\n",
      "Accuracy: 0.621217723486249\n",
      "F1 Score: 0.646157881321182\n",
      "MCC: 0.23870814782814875\n",
      "Balanced Accuracy: 0.6194664695936424\n",
      "------------------------------\n",
      "Results for J-P:\n",
      "Accuracy: 0.5781092127091214\n",
      "F1 Score: 0.5182412203261247\n",
      "MCC: 0.14713168166080184\n",
      "Balanced Accuracy: 0.5746841826708493\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# List to store models and performance metrics\n",
    "models = {}\n",
    "accuracy_scores = {}\n",
    "f1_scores = {}\n",
    "mcc_scores = {}\n",
    "balanced_accuracy_scores = {}\n",
    "\n",
    "print(\"CatBoost Results\")\n",
    "# Train and evaluate a model for each binary classification problem\n",
    "for column in y_train_binary.columns:\n",
    "    # Initialize the CatBoostClassifier\n",
    "    model = CatBoostClassifier(verbose=0, task_type=\"GPU\", devices='0:1', auto_class_weights=\"Balanced\")\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train_binary[column])\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    y_pred = model.predict(X_valid)\n",
    "    \n",
    "    # Calculate accuracy and F1 score\n",
    "    accuracy = accuracy_score(y_valid_binary[column], y_pred)\n",
    "    f1 = f1_score(y_valid_binary[column], y_pred)\n",
    "    mcc = matthews_corrcoef(y_valid_binary[column], y_pred)\n",
    "    b_accuracy = balanced_accuracy_score(y_valid_binary[column], y_pred)\n",
    "    \n",
    "    # Store the model and metrics\n",
    "    models[column] = model\n",
    "    accuracy_scores[column] = accuracy\n",
    "    f1_scores[column] = f1\n",
    "    mcc_scores[column] = mcc\n",
    "    balanced_accuracy_scores[column] = b_accuracy\n",
    "    \n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Results for {column}:\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    print(f\"MCC: {mcc}\")\n",
    "    print(f\"Balanced Accuracy: {b_accuracy}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Results\n",
      "Results for I-E:\n",
      "Accuracy: 0.789082288179663\n",
      "F1 Score: 0.8819406399516566\n",
      "MCC: 0.044971229733140175\n",
      "Balanced Accuracy: 0.5025019540008622\n",
      "------------------------------\n",
      "Results for N-S:\n",
      "Accuracy: 0.9262813224794215\n",
      "F1 Score: 0.9617108767072361\n",
      "MCC: 0.06286912107341662\n",
      "Balanced Accuracy: 0.5031489930147138\n",
      "------------------------------\n",
      "Results for T-F:\n",
      "Accuracy: 0.6284624525701586\n",
      "F1 Score: 0.6793414267040276\n",
      "MCC: 0.2463223996726144\n",
      "Balanced Accuracy: 0.6199122553433498\n",
      "------------------------------\n",
      "Results for J-P:\n",
      "Accuracy: 0.6161875404105215\n",
      "F1 Score: 0.32465399789858956\n",
      "MCC: 0.149019797620079\n",
      "Balanced Accuracy: 0.5556106788424128\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# List to store models and performance metrics\n",
    "models = {}\n",
    "accuracy_scores = {}\n",
    "f1_scores = {}\n",
    "mcc_scores = {}\n",
    "balanced_accuracy_scores = {}\n",
    "\n",
    "\n",
    "print(\"XGBoost Results\")\n",
    "# Train and evaluate a model for each binary classification problem\n",
    "for column in y_train_binary.columns:\n",
    "    # Initialize the CatBoostClassifier\n",
    "    model = XGBClassifier(device=\"cuda\")\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train_binary[column])\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    y_pred = model.predict(X_valid)\n",
    "    \n",
    "    # Calculate accuracy and F1 score\n",
    "    accuracy = accuracy_score(y_valid_binary[column], y_pred)\n",
    "    f1 = f1_score(y_valid_binary[column], y_pred)\n",
    "    mcc = matthews_corrcoef(y_valid_binary[column], y_pred)\n",
    "    b_accuracy = balanced_accuracy_score(y_valid_binary[column], y_pred)\n",
    "    \n",
    "    # Store the model and metrics\n",
    "    models[column] = model\n",
    "    accuracy_scores[column] = accuracy\n",
    "    f1_scores[column] = f1\n",
    "    mcc_scores [column] = mcc\n",
    "    balanced_accuracy_scores[column] = b_accuracy\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Results for {column}:\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    print(f\"MCC: {mcc}\")\n",
    "    print(f\"Balanced Accuracy: {b_accuracy}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Results\n",
      "Results for I-E:\n",
      "Accuracy: 0.5760607576515531\n",
      "F1 Score: 0.6826698793468866\n",
      "MCC: 0.11988924335941593\n",
      "Balanced Accuracy: 0.5730784104707725\n",
      "------------------------------\n",
      "Results for N-S:\n",
      "Accuracy: 0.5840311460077865\n",
      "F1 Score: 0.7217824963995382\n",
      "MCC: 0.09698417816655301\n",
      "Balanced Accuracy: 0.5917365099954532\n",
      "------------------------------\n",
      "Results for T-F:\n",
      "Accuracy: 0.6203536550884138\n",
      "F1 Score: 0.6453526709604966\n",
      "MCC: 0.23697056562078328\n",
      "Balanced Accuracy: 0.6185967701511876\n",
      "------------------------------\n",
      "Results for J-P:\n",
      "Accuracy: 0.5781368945342237\n",
      "F1 Score: 0.5158218655822229\n",
      "MCC: 0.14561633368752608\n",
      "Balanced Accuracy: 0.5738694659968057\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier \n",
    "\n",
    "\n",
    "# List to store models and performance metrics\n",
    "models = {}\n",
    "accuracy_scores = {}\n",
    "f1_scores = {}\n",
    "mcc_scores = {}\n",
    "balanced_accuracy_scores = {}\n",
    "\n",
    "print(\"LightGBM Results\")\n",
    "# Train and evaluate a model for each binary classification problem\n",
    "for column in y_train_binary.columns:\n",
    "    # Initialize the CatBoostClassifier\n",
    "    model = LGBMClassifier(verbose=0, is_unbalance=True)\n",
    "        \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train_binary[column])\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    y_pred = model.predict(X_valid)\n",
    "    \n",
    "    # Calculate accuracy and F1 score\n",
    "    accuracy = accuracy_score(y_valid_binary[column], y_pred)\n",
    "    f1 = f1_score(y_valid_binary[column], y_pred)\n",
    "    mcc = matthews_corrcoef(y_valid_binary[column], y_pred)\n",
    "    b_accuracy = balanced_accuracy_score(y_valid_binary[column], y_pred)\n",
    "    \n",
    "    # Store the model and metrics\n",
    "    models[column] = model\n",
    "    accuracy_scores[column] = accuracy\n",
    "    f1_scores[column] = f1\n",
    "    mcc_scores[column] = mcc\n",
    "    balanced_accuracy_scores[column] = b_accuracy\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Results for {column}:\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    print(f\"MCC: {mcc}\")\n",
    "    print(f\"Balanced Accuracy: {b_accuracy}\")\n",
    "    print(\"-\" * 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
