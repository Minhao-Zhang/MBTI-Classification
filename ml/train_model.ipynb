{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "DATA_PATH = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{DATA_PATH}train.pkl\", 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "train, valid = train_test_split(data, test_size=0.2, random_state=42, stratify=data['mbti'], shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "y_train = train['mbti']\n",
    "X_train = train.drop('mbti', axis=1)\n",
    "y_valid = valid['mbti']\n",
    "X_valid = valid.drop('mbti', axis=1)\n",
    "\n",
    "# Convert y_train and y_valid to separate binary columns for each MBTI character\n",
    "y_train_binary = pd.DataFrame({\n",
    "    'I-E': y_train.apply(lambda x: 1 if x[0] == 'I' else 0),\n",
    "    'N-S': y_train.apply(lambda x: 1 if x[1] == 'N' else 0),\n",
    "    'T-F': y_train.apply(lambda x: 1 if x[2] == 'T' else 0),\n",
    "    'J-P': y_train.apply(lambda x: 1 if x[3] == 'J' else 0)\n",
    "})\n",
    "\n",
    "y_valid_binary = pd.DataFrame({\n",
    "    'I-E': y_valid.apply(lambda x: 1 if x[0] == 'I' else 0),\n",
    "    'N-S': y_valid.apply(lambda x: 1 if x[1] == 'N' else 0),\n",
    "    'T-F': y_valid.apply(lambda x: 1 if x[2] == 'T' else 0),\n",
    "    'J-P': y_valid.apply(lambda x: 1 if x[3] == 'J' else 0)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost Results\n",
      "Results for I-E:\n",
      "Accuracy: 0.5746311891123427\n",
      "F1 Score: 0.6809467381906142\n",
      "------------------------------\n",
      "Results for N-S:\n",
      "Accuracy: 0.5811285089184909\n",
      "F1 Score: 0.719181523296707\n",
      "------------------------------\n",
      "Results for T-F:\n",
      "Accuracy: 0.6211880643879252\n",
      "F1 Score: 0.646282404680712\n",
      "------------------------------\n",
      "Results for J-P:\n",
      "Accuracy: 0.5778482126438713\n",
      "F1 Score: 0.5179975979121703\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# List to store models and performance metrics\n",
    "models = {}\n",
    "accuracy_scores = {}\n",
    "f1_scores = {}\n",
    "\n",
    "print(\"CatBoost Results\")\n",
    "# Train and evaluate a model for each binary classification problem\n",
    "for column in y_train_binary.columns:\n",
    "    # Initialize the CatBoostClassifier\n",
    "    model = CatBoostClassifier(verbose=0, task_type=\"GPU\", devices='0:1', auto_class_weights=\"Balanced\")\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train_binary[column])\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    y_pred = model.predict(X_valid)\n",
    "    \n",
    "    # Calculate accuracy and F1 score\n",
    "    accuracy = accuracy_score(y_valid_binary[column], y_pred)\n",
    "    f1 = f1_score(y_valid_binary[column], y_pred)\n",
    "    \n",
    "    # Store the model and metrics\n",
    "    models[column] = model\n",
    "    accuracy_scores[column] = accuracy\n",
    "    f1_scores[column] = f1\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Results for {column}:\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/users/zhang/code/MBTI_Classifier/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [19:44:47] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for I-E:\n",
      "Accuracy: 0.789062515447447\n",
      "F1 Score: 0.8819199015344292\n",
      "------------------------------\n",
      "Results for N-S:\n",
      "Accuracy: 0.9262971406651943\n",
      "F1 Score: 0.9617189353396617\n",
      "------------------------------\n",
      "Results for T-F:\n",
      "Accuracy: 0.6283794070948517\n",
      "F1 Score: 0.6794415222033471\n",
      "------------------------------\n",
      "Results for J-P:\n",
      "Accuracy: 0.6161875404105215\n",
      "F1 Score: 0.32479024919647703\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# List to store models and performance metrics\n",
    "models = {}\n",
    "accuracy_scores = {}\n",
    "f1_scores = {}\n",
    "\n",
    "\n",
    "print(\"XGBoost Results\")\n",
    "# Train and evaluate a model for each binary classification problem\n",
    "for column in y_train_binary.columns:\n",
    "    # Initialize the CatBoostClassifier\n",
    "    model = XGBClassifier(device=\"cuda\")\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train_binary[column])\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    y_pred = model.predict(X_valid)\n",
    "    \n",
    "    # Calculate accuracy and F1 score\n",
    "    accuracy = accuracy_score(y_valid_binary[column], y_pred)\n",
    "    f1 = f1_score(y_valid_binary[column], y_pred)\n",
    "    \n",
    "    # Store the model and metrics\n",
    "    models[column] = model\n",
    "    accuracy_scores[column] = accuracy\n",
    "    f1_scores[column] = f1\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Results for {column}:\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Results\n",
      "Results for I-E:\n",
      "Accuracy: 0.5760607576515531\n",
      "F1 Score: 0.6826698793468866\n",
      "------------------------------\n",
      "Results for N-S:\n",
      "Accuracy: 0.5840311460077865\n",
      "F1 Score: 0.7217824963995382\n",
      "------------------------------\n",
      "Results for T-F:\n",
      "Accuracy: 0.6203536550884138\n",
      "F1 Score: 0.6453526709604966\n",
      "------------------------------\n",
      "Results for J-P:\n",
      "Accuracy: 0.5781368945342237\n",
      "F1 Score: 0.5158218655822229\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier \n",
    "\n",
    "\n",
    "# List to store models and performance metrics\n",
    "models = {}\n",
    "accuracy_scores = {}\n",
    "f1_scores = {}\n",
    "\n",
    "print(\"LightGBM Results\")\n",
    "# Train and evaluate a model for each binary classification problem\n",
    "for column in y_train_binary.columns:\n",
    "    # Initialize the CatBoostClassifier\n",
    "    model = LGBMClassifier(verbose=0, is_unbalance=True)\n",
    "        \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train_binary[column])\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    y_pred = model.predict(X_valid)\n",
    "    \n",
    "    # Calculate accuracy and F1 score\n",
    "    accuracy = accuracy_score(y_valid_binary[column], y_pred)\n",
    "    f1 = f1_score(y_valid_binary[column], y_pred)\n",
    "    \n",
    "    # Store the model and metrics\n",
    "    models[column] = model\n",
    "    accuracy_scores[column] = accuracy\n",
    "    f1_scores[column] = f1\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Results for {column}:\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    print(\"-\" * 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
