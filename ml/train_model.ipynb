{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "DATA_PATH = 'data/200/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{DATA_PATH}train_0.pkl\", 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "train, valid = train_test_split(data, test_size=0.2, random_state=42, stratify=data['mbti'], shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "y_train = train['mbti']\n",
    "X_train = train.drop('mbti', axis=1)\n",
    "y_valid = valid['mbti']\n",
    "X_valid = valid.drop('mbti', axis=1)\n",
    "\n",
    "# Convert y_train and y_valid to separate binary columns for each MBTI character\n",
    "y_train_binary = pd.DataFrame({\n",
    "    'I-E': y_train.apply(lambda x: 1 if x[0] == 'I' else 0),\n",
    "    'N-S': y_train.apply(lambda x: 1 if x[1] == 'N' else 0),\n",
    "    'T-F': y_train.apply(lambda x: 1 if x[2] == 'T' else 0),\n",
    "    'J-P': y_train.apply(lambda x: 1 if x[3] == 'J' else 0)\n",
    "})\n",
    "\n",
    "y_valid_binary = pd.DataFrame({\n",
    "    'I-E': y_valid.apply(lambda x: 1 if x[0] == 'I' else 0),\n",
    "    'N-S': y_valid.apply(lambda x: 1 if x[1] == 'N' else 0),\n",
    "    'T-F': y_valid.apply(lambda x: 1 if x[2] == 'T' else 0),\n",
    "    'J-P': y_valid.apply(lambda x: 1 if x[3] == 'J' else 0)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for I-E:\n",
      "Accuracy: 0.7881019399899555\n",
      "F1 Score: 0.8814823766890844\n",
      "------------------------------\n",
      "Results for N-S:\n",
      "Accuracy: 0.9246020159076841\n",
      "F1 Score: 0.9608222146023808\n",
      "------------------------------\n",
      "Results for T-F:\n",
      "Accuracy: 0.608211962298088\n",
      "F1 Score: 0.6683736771081003\n",
      "------------------------------\n",
      "Results for J-P:\n",
      "Accuracy: 0.6041065651315712\n",
      "F1 Score: 0.1366935791966992\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# List to store models and performance metrics\n",
    "models = {}\n",
    "accuracy_scores = {}\n",
    "f1_scores = {}\n",
    "\n",
    "# Train and evaluate a model for each binary classification problem\n",
    "for column in y_train_binary.columns:\n",
    "    # Initialize the CatBoostClassifier\n",
    "    model = CatBoostClassifier(verbose=0, task_type=\"GPU\", devices='0:1')\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train_binary[column])\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    y_pred = model.predict(X_valid)\n",
    "    \n",
    "    # Calculate accuracy and F1 score\n",
    "    accuracy = accuracy_score(y_valid_binary[column], y_pred)\n",
    "    f1 = f1_score(y_valid_binary[column], y_pred)\n",
    "    \n",
    "    # Store the model and metrics\n",
    "    models[column] = model\n",
    "    accuracy_scores[column] = accuracy\n",
    "    f1_scores[column] = f1\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Results for {column}:\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu24zmh/MBTI_Classifier/.venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [10:55:37] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for I-E:\n",
      "Accuracy: 0.7877048318714304\n",
      "F1 Score: 0.8811453568777974\n",
      "------------------------------\n",
      "Results for N-S:\n",
      "Accuracy: 0.924561137130777\n",
      "F1 Score: 0.960797047791306\n",
      "------------------------------\n",
      "Results for T-F:\n",
      "Accuracy: 0.6072775902544996\n",
      "F1 Score: 0.661205571928764\n",
      "------------------------------\n",
      "Results for J-P:\n",
      "Accuracy: 0.6033707471472454\n",
      "F1 Score: 0.2558888621075005\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# List to store models and performance metrics\n",
    "models = {}\n",
    "accuracy_scores = {}\n",
    "f1_scores = {}\n",
    "\n",
    "# Train and evaluate a model for each binary classification problem\n",
    "for column in y_train_binary.columns:\n",
    "    # Initialize the CatBoostClassifier\n",
    "    model = XGBClassifier(device=\"cuda\")\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train_binary[column])\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    y_pred = model.predict(X_valid)\n",
    "    \n",
    "    # Calculate accuracy and F1 score\n",
    "    accuracy = accuracy_score(y_valid_binary[column], y_pred)\n",
    "    f1 = f1_score(y_valid_binary[column], y_pred)\n",
    "    \n",
    "    # Store the model and metrics\n",
    "    models[column] = model\n",
    "    accuracy_scores[column] = accuracy\n",
    "    f1_scores[column] = f1\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Results for {column}:\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 539770, number of negative: 145181\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.265525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 51000\n",
      "[LightGBM] [Info] Number of data points in the train set: 684951, number of used features: 200\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.788042 -> initscore=1.313162\n",
      "[LightGBM] [Info] Start training from score 1.313162\n",
      "Results for I-E:\n",
      "Accuracy: 0.7881194594657728\n",
      "F1 Score: 0.8814879175295447\n",
      "------------------------------\n",
      "[LightGBM] [Info] Number of positive: 633277, number of negative: 51674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.276825 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 51000\n",
      "[LightGBM] [Info] Number of data points in the train set: 684951, number of used features: 200\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.924558 -> initscore=2.505953\n",
      "[LightGBM] [Info] Start training from score 2.505953\n",
      "Results for N-S:\n",
      "Accuracy: 0.9246487345098635\n",
      "F1 Score: 0.9608450644388946\n",
      "------------------------------\n",
      "[LightGBM] [Info] Number of positive: 366435, number of negative: 318516\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.260764 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 51000\n",
      "[LightGBM] [Info] Number of data points in the train set: 684951, number of used features: 200\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.534980 -> initscore=0.140148\n",
      "[LightGBM] [Info] Start training from score 0.140148\n",
      "Results for T-F:\n",
      "Accuracy: 0.6067052873778016\n",
      "F1 Score: 0.6674764112514997\n",
      "------------------------------\n",
      "[LightGBM] [Info] Number of positive: 275211, number of negative: 409740\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.240865 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 51000\n",
      "[LightGBM] [Info] Number of data points in the train set: 684951, number of used features: 200\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401797 -> initscore=-0.397985\n",
      "[LightGBM] [Info] Start training from score -0.397985\n",
      "Results for J-P:\n",
      "Accuracy: 0.6052511708849672\n",
      "F1 Score: 0.1577662039921254\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier \n",
    "\n",
    "\n",
    "# List to store models and performance metrics\n",
    "models = {}\n",
    "accuracy_scores = {}\n",
    "f1_scores = {}\n",
    "\n",
    "# Train and evaluate a model for each binary classification problem\n",
    "for column in y_train_binary.columns:\n",
    "    # Initialize the CatBoostClassifier\n",
    "    model = LGBMClassifier()\n",
    "        \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train_binary[column])\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    y_pred = model.predict(X_valid)\n",
    "    \n",
    "    # Calculate accuracy and F1 score\n",
    "    accuracy = accuracy_score(y_valid_binary[column], y_pred)\n",
    "    f1 = f1_score(y_valid_binary[column], y_pred)\n",
    "    \n",
    "    # Store the model and metrics\n",
    "    models[column] = model\n",
    "    accuracy_scores[column] = accuracy\n",
    "    f1_scores[column] = f1\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Results for {column}:\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    print(\"-\" * 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
